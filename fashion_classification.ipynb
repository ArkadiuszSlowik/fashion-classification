{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Fashion classification </h1>\n",
    "\n",
    "Data set:\n",
    "\n",
    "https://www.kaggle.com/datasets/zalando-research/fashionmnist\n",
    "\n",
    "- Each row is a separate image\n",
    "\n",
    "- Column 1 is the class label.\n",
    "\n",
    "- Remaining columns are pixel numbers (784 total).\n",
    "\n",
    "- Each value is the darkness of the pixel (1 to 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Project goals </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CLassification of labeled data using softmax regression classifier\n",
    "\n",
    "- Practical use of the knowledge of chapters 2 and 4 of the book: Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Functions </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_fashion(x, y):\n",
    "    \"\"\"\n",
    "    Describes given fashion.\n",
    "    input: x - row of X, y - target value\n",
    "    \"\"\"\n",
    "    \n",
    "    fashion = {0: 'T-shirt/top', 1: 'Trouser', 2: 'Pullover',\n",
    "               3: 'Dress', 4: 'Coat', 5: 'Sandal', 6: 'Shirt',\n",
    "               7: 'Sneaker', 8: 'Bag', 9: 'Ankle boot'}\n",
    "    \n",
    "    pixels_to_image(x, 28, 28)\n",
    "    \n",
    "    print(fashion[y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Settings and libraries </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import opendatasets as od\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, precision_recall_curve, roc_curve, roc_auc_score, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_curve, roc_auc_score\n",
    "\n",
    "%run ml_functions.ipynb\n",
    "%run custom_transformers.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# od.download(\n",
    "#     \"https://www.kaggle.com/datasets/zalando-research/fashionmnist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> First look </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"fashionmnist/fashion-mnist_train.csv\")\n",
    "df_test = pd.read_csv(\"fashionmnist/fashion-mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      2       0       0       0       0       0       0       0       0   \n",
       "1      9       0       0       0       0       0       0       0       0   \n",
       "2      6       0       0       0       0       0       0       0       5   \n",
       "3      0       0       0       0       1       2       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0        30        43         0   \n",
       "3       0  ...         3         0         0         0         0         1   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 785)\n",
      "(10000, 785)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate class label column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train[\"label\"]\n",
    "X_train = df_train.drop(\"label\", axis=1)\n",
    "\n",
    "y_test = df_test[\"label\"]\n",
    "X_test = df_test.drop(\"label\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert numerical dfs to numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to_numpy()\n",
    "y_train = y_train.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show sample cloth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAKgElEQVR4nO3dX2jO7x/H8WvGxjb/Z9iwlWKSZss44cgRjnfAgXKghCNH44QDpaSkpJRzagciygEOlEhSSBKt0Wb5szH/Ddv35Nev38E+r7fvrt/yuvV8HO7Vde9zf+69umvvrutTNjo6mgD4mfSnLwDA2CgnYIpyAqYoJ2CKcgKmJgc5/8oFJl7ZWD/kmxMwRTkBU5QTMEU5AVOUEzBFOQFTlBMwRTkBU5QTMEU5AVOUEzBFOQFTlBMwRTkBU5QTMEU5AVOUEzBFOQFTlBMwRTkBU5QTMEU5AVPR0Zh/zM+fP2U+ebLtpacbN27IvKxszJMQU0opNTc3y7Xfvn2TeUVFhcx7e3tl3tXVVZht2bJFrt2wYYPM8e/wzQmYopyAKcoJmKKcgCnKCZiinIApygmYKhsdlU/5+ysfAXju3DmZHz9+XOZ9fX0yLy8vl/mLFy8Ks2PHjsm17e3tMr98+bLMjx49KvPa2trCrKamRq7t6emReWdnp8yPHDki878YjwAESgnlBExRTsAU5QRMUU7AFOUETFFOwFTJzjnv378v87a2tsJs7ty5cu2PHz9kPnPmTJlPmzZN5srQ0JDMDxw4IPMrV67IPJrRqv2iX79+lWu/f/8u88HBQZkPDw8XZg8ePJBrV61aJXNzzDmBUkI5AVOUEzBFOQFTlBMwRTkBU5QTMDWhc0712urs1t+xYsUKmat53fTp0+Xa6MzcL1++yDy4p2nq1Knj/t3d3d0yr6urk/mMGTNk/uvXr8JsypQpcq2aU6YUf+ZqDhrNf6N7HonW5/69BphzAqWEcgKmKCdginICpignYIpyAqbkc/Ry/72c8+/nQ4cOyfzVq1cyb2xsLMzevXs3nkv6r9mzZ8s82lql7kt1dbVc29LSInM1Ckkppc+fP8tcjVqitdFWuU+fPsl88eLFhdmkSfp7ZPfu3TI/deqUzCd4VDIufHMCpignYIpyAqYoJ2CKcgKmKCdginICprK2jI2MjMgXj2ZTypw5c2QeHU+ptmWpLKV4Vhi97yivrKwszNRWt5TieVzubHry5OLRd3RkaCS67yofGBiQa58+fSrzDx8+yDzaRqg+05y/8/9gyxhQSignYIpyAqYoJ2CKcgKmKCdginICpuR+zkjOnLOrq0uuraqqknk0l1LzQjVnTCnet6hmgSnFR0iqfY3R2tx9h9EcVB3NGb3v6NqiI0WV6HcvWLBA5tu3b5f5+fPnZf5/mGX+a3xzAqYoJ2CKcgKmKCdginICpignYIpyAqYm9BGAyvLly2X+/ft3mUdnpKq9gbnn7Ubnr0Z7B3P2mkZn4kZ5NEfNmXNGeXTer9ovGu2xjT6z9+/fy/zWrVsyV+cgR49tjO5LYj8nUFooJ2CKcgKmKCdginICpignYIpyAqbknHM0GIJGs6U3b94UZmvWrJFro/2aETUHjc6GjeaUTU1NMl+7dq3My8vLC7ObN2/KtatXr5Z5tGcyOg9YPR+0u7tbrn327JnM+/v7ZT5r1qzCLPpMoj26g4ODMl+3bp3ML1y4IPNMzDmBUkI5AVOUEzBFOQFTlBMwRTkBU3IvS+4xjKdPny7MoiMac7Y2pZTS8PDwuF872p60dOlSmbe2tsr848ePhdm9e/fk2mirXEtLi8zVeCullF6+fFmYRVufoscy9vb2ylz9TVRUVMi10WeqxjQppXTx4kWZq88sGvuN97GMfHMCpignYIpyAqYoJ2CKcgKmKCdginICpib0aMwlS5YUZtEWn+gYRTXHTEnPaHMfVRdtGWtoaJC5eu+PHj2Sa+fPny/zaB4YzYfVHFRtdUsp3tY1MDAgc/X6uY/gi6799evXMu/o6CjMTp48Oa5r+h9sGQNKCeUETFFOwBTlBExRTsAU5QRMUU7AVNac8+HDh/LFN2/eXJjV1dXJtdGsMdpbqB4hqB41l1I8B40esxetz3kEYHRfomuL5stqX2Q0a4z2wY6MjMhc3bdofhu9r+g41Ojv6fHjx4VZtF/zNzDnBEoJ5QRMUU7AFOUETFFOwBTlBExRTsCUHu4Ejh8/LnM1t4pmZtG8L9qXqM53jfb2RWfDRnsqo5mamotF87rojNTovUUzXjWrjO559LvV7DmlvHlh9L6iOWY0R503b15hFu3n3Lt3r8yL8M0JmKKcgCnKCZiinIApygmYopyAKcoJmMraz6lmP1EezRJzzqWN8mgmVlNTI/OcvaQp6T2Z0Z7HaJYYzY+jXL1+dN+izzSa/6r7Fr3vSDQ/jmas6kze6H319/fLPLGfEygtlBMwRTkBU5QTMEU5AVOUEzAlZwJ3796Vi9++fSvzRYsWFWbqCMaU4mMWo1GLGndEo5DotaORQvTeZsyYUZjljBtSikcxOXKPDM15PKG6Zyml1NfXJ/NolBJ95tXV1YVZ9HlHo5SFCxeO+XO+OQFTlBMwRTkBU5QTMEU5AVOUEzBFOQFTcuB3/fp1uXjZsmUyV3OtaF6XS22NirZNRduHohlszrGdVVVVcm3utefk0bat3Pvy/PnzwmzPnj1ybW1trcw7Oztl3t7eLnN1X6I55tmzZ2W+b9++MX/ONydginICpignYIpyAqYoJ2CKcgKmKCdgSh6N2dHRIYdiV69elS/e0NBQmEXHKA4ODso82kOn3lf0eMFolhjta4zmeeraor2m0bVF+zlz8uh9RZ9JNCcdGhoqzKK9w+roypRSampqkrk6rjQlfe2tra1y7ZkzZ2ReX1/P0ZhAKaGcgCnKCZiinIApygmYopyAKcoJmJJDtcOHD8vF9fX1Mr99+3ZhdufOHbl2x44dMl+5cqXM9+/fX5i1tbXJtdFe02hPZDTPU6+f+5i9aAab84jAaAYbnbmb8xi/3EcA9vT0yHzjxo0y37VrV2HW0dExnksK8c0JmKKcgCnKCZiinIApygmYopyAKfm/8eXLl8vFJ06cGPcvVscgppRSY2OjzA8ePChztb0pOn4yd5QSUUeGRq8dbduKRKOUHNG4I+cRgJs2bRrXNf2ua9euTejrjwffnIApygmYopyAKcoJmKKcgCnKCZiinIApOeeMjlHMmZlFc8xIc3OzzNW88OvXr3JtdHRmZWWlzKNZZPSoPCX6THIfAaheP3dGGm1nU3PS6urqrN+dc88judv0CteNaxWACUc5AVOUEzBFOQFTlBMwRTkBU5QTMCXnnLlzLTVTy32c3NatW2W+bdu2wmxgYECujY54HB4elnl0hKTKJ/Joy9+h1kfHdkbXHh3rqR7jt379erk2MlGzyInkd0UAUkqUE7BFOQFTlBMwRTkBU5QTMEU5AVNlwf6+vANa/6CdO3cWZk+ePJFro0cb5u6pzNlbGM0ac+egKo/WRvPd6NxaNX++dOmSXBuJPpNoDqrWR2t/w5gvwDcnYIpyAqYoJ2CKcgKmKCdginICpignYOqvnXMCJYQ5J1BKKCdginICpignYIpyAqYoJ2CKcgKmKCdginICpignYIpyAqYoJ2CKcgKmKCdginICpignYIpyAqYoJ2CKcgKmKCdginICpignYEo/s63gyD4AE49vTsAU5QRMUU7AFOUETFFOwBTlBEz9AzYG+CEGusjMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pullover\n"
     ]
    }
   ],
   "source": [
    "describe_fashion(X_train[0], y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if columns are constant or quasi-constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector = VarianceThreshold(0.01)\n",
    "selector.fit_transform(df_train)\n",
    "df_train.shape[1] - sum(selector.get_support())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is only 1 quasi-column for 0.01 threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no const. columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9    6000\n",
       "8    6000\n",
       "7    6000\n",
       "6    6000\n",
       "5    6000\n",
       "4    6000\n",
       "3    6000\n",
       "2    6000\n",
       "1    6000\n",
       "0    6000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels are equally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Data preprocessing </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pullover\n"
     ]
    }
   ],
   "source": [
    "X = X_train.copy()\n",
    "\n",
    "pipeline_scaler = Pipeline([\n",
    "    ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "X_scaled = pipeline_scaler.fit_transform(X)\n",
    "describe_fashion(X_scaled[0], y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Black = 0 and white > 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X_train.copy()\n",
    "\n",
    "# pipeline_binary0 = Pipeline([\n",
    "#     ('pixel_to_binary', PixeltoBinary()),\n",
    "#     ])\n",
    "\n",
    "# X_binared0 = pipeline_binary0.fit_transform(X)\n",
    "# describe_fashion(X_binared0[0], y_train[0])\n",
    "\n",
    "# np.count_nonzero(X_binared0) / np.product(X_binared0.shape)\n",
    "\n",
    "# print('On average half of the pixels on an image are not white.'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Black <= 128 and white > 128:'')\n",
    "\n",
    "# X = X_train.copy()\n",
    "\n",
    "# pipeline_binary128 = Pipeline([\n",
    "#     ('pixel_to_binary', PixeltoBinary(floor=128)),\n",
    "#     ])\n",
    "\n",
    "# X_binared128 = pipeline_binary128.fit_transform(X)\n",
    "# describe_fashion(X_binared128[0], y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Constant and quasi-constant columns')\n",
    "\n",
    "# X = X_train.copy()\n",
    "\n",
    "# columns = np.arange(0, X_train.shape[1], 1)\n",
    "\n",
    "# pipeline_constant = ColumnTransformer([\n",
    "#  (\"num\", DropConstantColumn(threshold=0.01), columns),\n",
    "#  ])\n",
    "\n",
    "# X_noconst = pipeline_constant.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Softmax regression classifier </h2>\n",
    "\n",
    "Now we will use softmax regression classifier usinf sklearn, for prediction.\n",
    "\n",
    "As we know, it's preferable to have at least a little bit of regularization. Lasso or Elastic Net are a good choices, if we suspect, that only a few features have a big impact. It's not our case. That's why we will try to regularize with a Ridge. Additonally, we will use early stopping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin with a plain model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_, X_cv, y_, y_cv = train_test_split(X_scaled, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(fit_intercept=False, multi_class='multinomial',\n",
       "                   penalty='none')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(penalty='none', multi_class='multinomial', fit_intercept=False, max_iter=100)\n",
    "\n",
    "model.fit(X_, y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "y_cv_pred = cross_val_predict(model, X_cv, y_cv)\n",
    "y_cv_pred_proba = cross_val_predict(model, X_cv, y_cv, method='predict_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = confusion_matrix(y_cv, y_cv_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T-shirt/top</th>\n",
       "      <th>Trouser</th>\n",
       "      <th>Pullover</th>\n",
       "      <th>Dress</th>\n",
       "      <th>Coat</th>\n",
       "      <th>Sandal</th>\n",
       "      <th>Shirt</th>\n",
       "      <th>Sneaker</th>\n",
       "      <th>Bag</th>\n",
       "      <th>Ankle boot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T-shirt/top</th>\n",
       "      <td>932</td>\n",
       "      <td>12</td>\n",
       "      <td>36</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>172</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trouser</th>\n",
       "      <td>8</td>\n",
       "      <td>1113</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pullover</th>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>844</td>\n",
       "      <td>19</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dress</th>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>30</td>\n",
       "      <td>1003</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coat</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>151</td>\n",
       "      <td>57</td>\n",
       "      <td>803</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sandal</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1007</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shirt</th>\n",
       "      <td>191</td>\n",
       "      <td>6</td>\n",
       "      <td>165</td>\n",
       "      <td>45</td>\n",
       "      <td>126</td>\n",
       "      <td>2</td>\n",
       "      <td>683</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sneaker</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>1108</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bag</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>1048</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ankle boot</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>1125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             T-shirt/top  Trouser  Pullover  Dress  Coat  Sandal  Shirt  \\\n",
       "T-shirt/top          932       12        36     50    10       6    172   \n",
       "Trouser                8     1113         6     30     7       0      8   \n",
       "Pullover              22        7       844     19   147       3    149   \n",
       "Dress                 47       47        30   1003    58       1     49   \n",
       "Coat                   9        4       151     57   803       2    150   \n",
       "Sandal                 1        1         1      1     0    1007      0   \n",
       "Shirt                191        6       165     45   126       2    683   \n",
       "Sneaker                0        0         0      0     0      67      0   \n",
       "Bag                   10        4        10      9     6      19     29   \n",
       "Ankle boot             0        0         0      0     0      30      1   \n",
       "\n",
       "             Sneaker   Bag  Ankle boot  \n",
       "T-shirt/top        2    12           0  \n",
       "Trouser            1     1           0  \n",
       "Pullover           0     8           1  \n",
       "Dress              1     3           3  \n",
       "Coat               0     9           0  \n",
       "Sandal            77    16          37  \n",
       "Shirt              0    24           1  \n",
       "Sneaker         1108     2          47  \n",
       "Bag                9  1048           5  \n",
       "Ankle boot        52     2        1125  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "pd.DataFrame(con, index=fashion, columns=fashion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see our model is often wrong, when predicting T-shirt/Top, Pullover, Coat and Shirt, which are intuitively most similar parts of clothing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's measure precision, recall and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, f1_score = precision_recall_fscore_support(y_cv, y_cv_pred)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8072198150520127, 0.8072187825077579, 0.8071471966564465)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(precision), np.average(recall), np.average(f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, F1 favors classifiers which have similar precision and recall, and this is what we want in our case, so it will be our performance measure and there is no need to experiment with precision/recall tradeoff. Additionally, F1 score is preffered for multiclass classification over ROC AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Hyperparameter tuning </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/areczek/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(max_iter=400,\n",
       "                                          multi_class='multinomial',\n",
       "                                          random_state=42),\n",
       "             param_grid={'C': [10, 1, 0.1, 0.01, 0.001],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'sag', 'saga']})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(multi_class='multinomial', max_iter=400, random_state=42, penalty='l2')\n",
    "\n",
    "parameters = {'C': [10, 1, 0.1, 0.01, 0.001],\n",
    "              'solver': ['newton-cg', 'lbfgs', 'sag', 'saga']}\n",
    "\n",
    "model = GridSearchCV(model, parameters)\n",
    "\n",
    "model.fit(X_, y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if we set max_features hyperparameter to 1000, max_iter is reached for the models that warnings refer to, what I check on Google Colab:\n",
    "\n",
    "https://colab.research.google.com/drive/1hB2aPWlFX2shlonTnbtdNvft4jGQ9FQp?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check model of which parameters was best and tune again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.01, 'solver': 'newton-cg'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(max_iter=400,\n",
       "                                          multi_class='multinomial',\n",
       "                                          random_state=42, solver='newton-cg'),\n",
       "             param_grid={'C': [0.003, 0.005, 0.01, 0.03, 0.05]})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(multi_class='multinomial', max_iter=400, random_state=42, penalty='l2', solver='newton-cg')\n",
    "\n",
    "parameters = {'C': [0.003, 0.005, 0.01, 0.03, 0.05] }\n",
    "\n",
    "model = GridSearchCV(model, parameters)\n",
    "\n",
    "model.fit(X_, y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.01}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see a best finded model is for newton-cg solver and C=0.01. Let's make some predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cv_pred = cross_val_predict(model, X_cv, y_cv)\n",
    "y_cv_pred_proba = cross_val_predict(model, X_cv, y_cv, method='predict_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, f1_score = precision_recall_fscore_support(y_cv, y_cv_pred)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8427606975984322, 0.8434101913763603, 0.8428416182741575)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(precision), np.average(recall), np.average(f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see with a pretty similar values of precision and recall f1_score equals around 0.84. It's better than before (f1_score was equal around 0.81)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time for error analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T-shirt/top</th>\n",
       "      <th>Trouser</th>\n",
       "      <th>Pullover</th>\n",
       "      <th>Dress</th>\n",
       "      <th>Coat</th>\n",
       "      <th>Sandal</th>\n",
       "      <th>Shirt</th>\n",
       "      <th>Sneaker</th>\n",
       "      <th>Bag</th>\n",
       "      <th>Ankle boot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T-shirt/top</th>\n",
       "      <td>1009</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trouser</th>\n",
       "      <td>6</td>\n",
       "      <td>1116</td>\n",
       "      <td>9</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pullover</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>892</td>\n",
       "      <td>11</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dress</th>\n",
       "      <td>44</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>1088</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coat</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>116</td>\n",
       "      <td>49</td>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sandal</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1033</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shirt</th>\n",
       "      <td>194</td>\n",
       "      <td>4</td>\n",
       "      <td>135</td>\n",
       "      <td>41</td>\n",
       "      <td>129</td>\n",
       "      <td>2</td>\n",
       "      <td>718</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sneaker</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1130</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bag</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>1080</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ankle boot</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>1144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             T-shirt/top  Trouser  Pullover  Dress  Coat  Sandal  Shirt  \\\n",
       "T-shirt/top         1009        6        16     57     3       5    125   \n",
       "Trouser                6     1116         9     35     3       0      5   \n",
       "Pullover              14        2       892     11   157       0    117   \n",
       "Dress                 44       14        13   1088    48       0     32   \n",
       "Coat                   3        4       116     49   893       0    115   \n",
       "Sandal                 2        0         1      2     0    1033      0   \n",
       "Shirt                194        4       135     41   129       2    718   \n",
       "Sneaker                0        0         0      0     0      56      0   \n",
       "Bag                    8        1         5     10     2       8     26   \n",
       "Ankle boot             0        1         0      0     0      20      1   \n",
       "\n",
       "             Sneaker   Bag  Ankle boot  \n",
       "T-shirt/top        0    11           0  \n",
       "Trouser            0     0           0  \n",
       "Pullover           0     7           0  \n",
       "Dress              0     3           0  \n",
       "Coat               0     5           0  \n",
       "Sandal            70     9          24  \n",
       "Shirt              0    19           1  \n",
       "Sneaker         1130     0          38  \n",
       "Bag                7  1080           2  \n",
       "Ankle boot        43     1        1144  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con = confusion_matrix(y_cv, y_cv_pred)\n",
    "\n",
    "fashion = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "pd.DataFrame(con, index=fashion, columns=fashion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance, errors of recognizing clothes are the same type as before. It's time to use matshow function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(con, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of instances were classified correctly, that's why main diagonal is bright. However indexes 0,2,4 and 6 are darker than others. It could mean that, there are fewer images of this kind or classifier doesn't perform that good for these clothes. As we know labels are quite good balanced, also the dataset opts for the second idea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's focus our plot on errors. We will replace pure number with ratios (divide each value by number of instances of corresponding class) and set 0 for diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "row_sums = con.sum(axis=1, keepdims=True)\n",
    "normalized_con = con / row_sums\n",
    "\n",
    "np.fill_diagonal(normalized_con, 0)\n",
    "plt.matshow(normalized_con, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns with index 4 and 6 are quire bright, which means many of instances get missclassified as Coat or Shirt. Also rows of these clothes are bright. This time, it means that Shirts and Coats are sometimes classified wrong.\n",
    "As we can see, the biggest error is because of the situation that Shirts are predicted as T-shirts / Tops.\n",
    "The reason of these errors is a high similarity of these clothes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, our idea is to analyze these errors to gain insights why exactly our classifier makes these wrong predictions and what kind of transformation or additional features may help to imporve predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Let's start by displaying  1vs1 using imshow..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

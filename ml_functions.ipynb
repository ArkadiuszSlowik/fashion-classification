{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn.gaussian_process.kernels import RBF, Sum, ConstantKernel, DotProduct, ExpSineSquared, Matern, PairwiseKernel, RationalQuadratic, RBF, WhiteKernel\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "import union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> All-purpose </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores:list):\n",
    "    \"\"\"\n",
    "    Displays scores, mean, and std.\n",
    "    \"\"\"\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attributes(attribute:dict={}) -> list:\n",
    "    \"\"\"\n",
    "    Returns list of dictionaries - different combinations of hyperparameters values ready to put in a model.\n",
    "    \n",
    "    input f.e.:\n",
    "    attribute = {'loss': ['ls', 'lad', 'huber', 'quantile'],\n",
    "     'criterion': ['friedman_mse', 'squared_error', 'mse'],\n",
    "     'max_features': [None, 'auto', 'sqrt', 'log2']\n",
    "                }\n",
    "    \"\"\"\n",
    "    \n",
    "    attribute_names = []\n",
    "    attribute_values = []\n",
    "    final_attr_list = []\n",
    "    \n",
    "    for k,v in sorted(attribute.items()):\n",
    "        attribute_names.append(k)\n",
    "        attribute_values.append(v)\n",
    "    \n",
    "    for attr_composition in itertools.product(*attribute_values):\n",
    "        new_dic = {}\n",
    "        for i in range(len(attribute_names)):\n",
    "            new_dic[attribute_names[i]] = attr_composition[i]\n",
    "        final_attr_list.append(new_dic)\n",
    "        \n",
    "    return final_attr_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Regression </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_randomized_tuning(X:np.ndarray, y:np.ndarray, distributions:dict, model, n_iter:int=1, r_state:int=None, cv:int=4) -> [float, float, dict]:\n",
    "    \"\"\"\n",
    "    Hyperparameter tuning for regression model.\n",
    "    \"\"\"\n",
    "    reg = RandomizedSearchCV(model, distributions, n_iter=n_iter, random_state=r_state)\n",
    "\n",
    "    reg.fit(X, y)\n",
    "\n",
    "    predictions = reg.predict(X)\n",
    "    train_mse = mean_squared_error(predictions, y)\n",
    "    rmse_training = np.sqrt(train_mse)\n",
    "\n",
    "    scores = cross_val_score(reg, X, np.ravel(y),\n",
    "                                  scoring=\"neg_mean_squared_error\", cv=cv)\n",
    "\n",
    "    rmse_cv = np.sqrt(-scores).mean()\n",
    "    \n",
    "    return rmse_training, rmse_cv, reg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_linear_models(train_set_ready:np.ndarray, train_set_labels:np.ndarray, cv:int=4):\n",
    "    \"\"\"\n",
    "    Evaluation of linear models with some basic settings for training and cv set.\n",
    "    \"\"\"\n",
    "    \n",
    "    ridge_attrubites = {'solver': ['svd', 'lsqr', 'sag', 'cholesky', 'sparse_cg', 'saga']}\n",
    "    \n",
    "    sgd_attributes = {'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "                      'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive']}\n",
    "    \n",
    "    models = {'LinearRegression': {'attr': [{}]},\n",
    "               'Ridge': {'attr': attributes(ridge_attrubites)},\n",
    "               'Lasso': {'attr': [{'selection': 'cyclic'}, {'selection': 'random'}]},\n",
    "               'ElasticNet': {'attr': [{'selection': 'cyclic'}, {'selection': 'random'}]},\n",
    "               'Lars': {'attr': [{}]},\n",
    "               'LassoLars': {'attr': [{}]},\n",
    "               'OrthogonalMatchingPursuit': {'attr': [{}]},\n",
    "               'BayesianRidge': {'attr': [{}]},\n",
    "               'ARDRegression': {'attr': [{}]},\n",
    "               'LogisticRegression': {'attr': [{'penalty': 'l1', 'solver': 'liblinear'},\n",
    "                                              {'penalty': 'l1', 'solver': 'saga'},\n",
    "                                              {'penalty': 'l2', 'solver': 'newton-cg'},\n",
    "                                              {'penalty': 'l2', 'solver': 'lbfgs'},\n",
    "                                              {'penalty': 'l2', 'solver': 'liblinear'},\n",
    "                                              {'penalty': 'l2', 'solver': 'sag'},\n",
    "                                              {'penalty': 'l2', 'solver': 'saga'},\n",
    "                                              {'penalty': 'elasticnet', 'solver': 'saga', 'l1_ratio':0.5},\n",
    "                                              {'penalty': 'none', 'solver': 'newton-cg'},\n",
    "                                              {'penalty': 'none', 'solver': 'lbfgs'},\n",
    "                                              {'penalty': 'none', 'solver': 'sag'},\n",
    "                                              {'penalty': 'none', 'solver': 'saga'}]},\n",
    "               'SGDRegressor': {'attr': attributes(sgd_attributes)},\n",
    "               'PassiveAggressiveRegressor': {'attr': [{'loss': 'epsilon_insensitive'},\n",
    "                                                       {'loss': 'squared_epsilon_insensitive'}]},\n",
    "               'HuberRegressor': {'attr': [{}]},\n",
    "               'TweedieRegressor': {'attr': [{'link': 'identity'}, {'link': 'log'}]},\n",
    "               'TheilSenRegressor': {'attr': [{}]},\n",
    "               'RANSACRegressor': {'attr': [{}]}\n",
    "              }\n",
    "\n",
    "    final_models = {}\n",
    "    \n",
    "    train_set_labels = np.ravel(train_set_labels)\n",
    "    for k,v in sorted(models.items()):\n",
    "        print(k,': ')\n",
    "        print(v['attr'])\n",
    "        for i in range(len(v['attr'])):\n",
    "            fun = getattr(linear_model, k)\n",
    "            reg = fun(**v['attr'][i])\n",
    "            reg.fit(train_set_ready, train_set_labels)\n",
    "\n",
    "            predictions = reg.predict(train_set_ready)\n",
    "\n",
    "            train_mse = mean_squared_error(predictions, train_set_labels)\n",
    "            rmse_training = np.sqrt(train_mse)\n",
    "\n",
    "            scores = cross_val_score(reg, train_set_new_ready, np.ravel(train_set_labels),\n",
    "                                          scoring=\"neg_mean_squared_error\", cv=cv)\n",
    "\n",
    "            rmse_cv = np.sqrt(-scores).mean()\n",
    "            \n",
    "            model_name = str(k) + str(v['attr'][i])\n",
    "            \n",
    "            final_models[model_name] = {'rmse_training': rmse_training, 'rmse_cv': rmse_cv}\n",
    "        \n",
    "    return final_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_kernelridge(train_set_ready:np.ndarray, train_set_labels:np.ndarray, cv:int=4):\n",
    "    \"\"\"\n",
    "    Evaluation of kernel ridge with some basic settings for training and cv set.\n",
    "    \"\"\"\n",
    "    kernels = [ConstantKernel(), DotProduct(), ExpSineSquared(), Matern(),\n",
    "              PairwiseKernel(), RationalQuadratic(), RBF(), WhiteKernel(),\n",
    "              'linear']\n",
    "    \n",
    "    final_models = {}\n",
    "    \n",
    "    for kernel in kernels:\n",
    "\n",
    "        reg = KernelRidge(kernel=kernel)\n",
    "        reg.fit(train_set_ready, train_set_labels)\n",
    "\n",
    "        predictions = reg.predict(train_set_new_ready)\n",
    "\n",
    "        reg_mse = mean_squared_error(predictions, train_set_labels)\n",
    "        rmse_training = np.sqrt(reg_mse)\n",
    "\n",
    "        reg_scores = cross_val_score(reg, train_set_new_ready, train_set_labels,\n",
    "                                     scoring=\"neg_mean_squared_error\", cv=cv)\n",
    "\n",
    "        rmse_cv = np.sqrt(-reg_scores).mean()\n",
    "        \n",
    "        final_models['KernelRidge ' + str(kernel)] = {'rmse_training': rmse_training, 'rmse_cv': rmse_cv}\n",
    "        \n",
    "    return final_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_svm(train_set_ready:np.ndarray, train_set_labels:np.ndarray, cv:int=4):\n",
    "    \"\"\"\n",
    "    Evaluation of svm models with some basic settings for training and cv set.\n",
    "    \"\"\"\n",
    "    \n",
    "    svr_attributes = {'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}\n",
    "    \n",
    "    nusvr_attributes = {'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}\n",
    "    \n",
    "    models = {'SVR': {'attr': attributes(svr_attributes)},\n",
    "              'NuSVR': {'attr': attributes(nusvr_attributes)},\n",
    "              'LinearSVR': {'attr': [{'loss': 'epsilon_insensitive'},\n",
    "                                     {'loss': 'squared_epsilon_insensitive'}]},\n",
    "             }\n",
    "    \n",
    "    final_models = {}\n",
    "    \n",
    "    train_set_labels = np.ravel(train_set_labels)\n",
    "    for k,v in sorted(models.items()):\n",
    "        print(k,': ')\n",
    "        print(v['attr'])\n",
    "        for i in range(len(v['attr'])):\n",
    "            fun = getattr(svm, k)\n",
    "            reg = fun(**v['attr'][i])\n",
    "            reg.fit(train_set_ready, train_set_labels)\n",
    "\n",
    "            predictions = reg.predict(train_set_ready)\n",
    "\n",
    "            train_mse = mean_squared_error(predictions, train_set_labels)\n",
    "            rmse_training = np.sqrt(train_mse)\n",
    "\n",
    "            scores = cross_val_score(reg, train_set_new_ready, np.ravel(train_set_labels),\n",
    "                                          scoring=\"neg_mean_squared_error\", cv=cv)\n",
    "\n",
    "            rmse_cv = np.sqrt(-scores).mean()\n",
    "            \n",
    "            model_name = str(k) + str(v['attr'][i])\n",
    "            \n",
    "            final_models[model_name] = {'rmse_training': rmse_training, 'rmse_cv': rmse_cv}\n",
    "        \n",
    "    return final_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_gaussianprocess(train_set_ready:np.ndarray, train_set_labels:np.ndarray, cv:int=4):\n",
    "    \"\"\"\n",
    "    Evaluation of gaussian process model with some basic settings for training and cv set.\n",
    "    \"\"\"\n",
    "    \n",
    "    kernels = [ConstantKernel(), DotProduct(), ExpSineSquared(), Matern(),\n",
    "              PairwiseKernel(), RationalQuadratic(), RBF(), WhiteKernel()]\n",
    "    \n",
    "    final_models = {}\n",
    "    \n",
    "    for kernel in kernels:\n",
    "        try:\n",
    "            reg = GaussianProcessRegressor(kernel=kernel)\n",
    "            reg.fit(train_set_ready, train_set_labels)\n",
    "\n",
    "            predictions = reg.predict(train_set_new_ready)\n",
    "\n",
    "            reg_mse = mean_squared_error(predictions, train_set_labels)\n",
    "            rmse_training = np.sqrt(reg_mse)\n",
    "\n",
    "            reg_scores = cross_val_score(reg, train_set_new_ready, train_set_labels,\n",
    "                                         scoring=\"neg_mean_squared_error\", cv=cv)\n",
    "\n",
    "            rmse_cv = np.sqrt(-reg_scores).mean()\n",
    "\n",
    "            final_models['GaussianProcessRegressor ' + str(kernel)] = {'rmse_training': rmse_training, 'rmse_cv': rmse_cv}\n",
    "        except Exception as e: print(e)\n",
    "            \n",
    "    return final_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_crossdecomposition(train_set_ready, train_set_labels, cv=4):\n",
    "    \"\"\"\n",
    "    Evaluation of cross decomposition models with some basic settings for training and cv set.\n",
    "    \"\"\"\n",
    "    \n",
    "    models = {'PLSRegression': {'attr': [{}]},\n",
    "              'PLSCanonical': {'attr': [{'algorithm': 'nipals'},\n",
    "                                        {'algorithm': 'svd'}]},\n",
    "              'CCA': {'attr': [{}]}\n",
    "             }\n",
    "    \n",
    "    final_models = {}\n",
    "    \n",
    "    train_set_labels = np.ravel(train_set_labels)\n",
    "    for k,v in sorted(models.items()):\n",
    "        print(k,': ')\n",
    "        print(v['attr'])\n",
    "        for i in range(len(v['attr'])):\n",
    "            fun = getattr(cross_decomposition, k)\n",
    "            reg = fun(**v['attr'][i])\n",
    "            reg.fit(train_set_ready, train_set_labels)\n",
    "\n",
    "            predictions = reg.predict(train_set_ready)\n",
    "\n",
    "            train_mse = mean_squared_error(predictions, train_set_labels)\n",
    "            rmse_training = np.sqrt(train_mse)\n",
    "\n",
    "            scores = cross_val_score(reg, train_set_new_ready, np.ravel(train_set_labels),\n",
    "                                          scoring=\"neg_mean_squared_error\", cv=cv)\n",
    "\n",
    "            rmse_cv = np.sqrt(-scores).mean()\n",
    "            \n",
    "            model_name = str(k) + str(v['attr'][i])\n",
    "            \n",
    "            final_models[model_name] = {'rmse_training': rmse_training, 'rmse_cv': rmse_cv}\n",
    "        \n",
    "    return final_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_decisiontree(train_set_ready:np.ndarray, train_set_labels:np.ndarray, cv:int=4):\n",
    "    \"\"\"\n",
    "    Evaluation of decision tree model with some basic settings for training and cv set.\n",
    "    \"\"\"\n",
    "    \n",
    "    criterion = ['mse', 'friedman_mse', 'mae', 'poisson']\n",
    "    splitter = ['best','random']\n",
    "    max_features = [None, 'auto', 'sqrt', 'log2']\n",
    "    \n",
    "    attributes = []\n",
    "    \n",
    "    for i in range(len(criterion)):\n",
    "        for j in range(len(splitter)):\n",
    "            for k in range(len(max_features)):\n",
    "                new_dic = {'criterion': criterion[i], 'splitter': splitter[j],\n",
    "                            'max_features': max_features[k]}\n",
    "                \n",
    "                attributes.append(new_dic)      \n",
    "                \n",
    "    final_models = {}\n",
    "    \n",
    "    for attr in attributes:\n",
    "\n",
    "        reg = tree.DecisionTreeRegressor(**attr)\n",
    "        reg.fit(train_set_ready, train_set_labels)\n",
    "\n",
    "        predictions = reg.predict(train_set_new_ready)\n",
    "\n",
    "        reg_mse = mean_squared_error(predictions, train_set_labels)\n",
    "        rmse_training = np.sqrt(reg_mse)\n",
    "\n",
    "        reg_scores = cross_val_score(reg, train_set_new_ready, train_set_labels,\n",
    "                                     scoring=\"neg_mean_squared_error\", cv=cv)\n",
    "\n",
    "        rmse_cv = np.sqrt(-reg_scores).mean()\n",
    "        \n",
    "        final_models['DecisionTreeRegressor ' + str(attr)] = {'rmse_training': rmse_training, 'rmse_cv': rmse_cv}\n",
    "        \n",
    "    return final_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_ensemble(train_set_ready:np.ndarray, train_set_labels:np.ndarray, cv:int=4):\n",
    "    \"\"\"\n",
    "    Evaluation of ensemble models with some basic settings for training and cv set.\n",
    "    \"\"\"\n",
    "    \n",
    "    estimators = [('ridge', RidgeCV()),\n",
    "          ('lasso', LassoCV(random_state=42)),\n",
    "          ('knr', KNeighborsRegressor(n_neighbors=20,\n",
    "                                      metric='euclidean'))]\n",
    "    \n",
    "    abr_attributes = {'loss': ['linear', 'square', 'exponential']}\n",
    "    \n",
    "    etr_attrubites = {'criterion': ['mse', 'mae'],\n",
    "                      'max_features': ['sqrt', 'log2', None, 1]}\n",
    "    \n",
    "    gbr_attributes = {'loss': ['ls', 'lad', 'huber', 'quantile'],\n",
    "     'criterion': ['friedman_mse', 'mse'],\n",
    "     'max_features': [None, 'auto', 'sqrt', 'log2']}\n",
    "    \n",
    "    rf_attributes = {'criterion': ['mse', 'mae', 'poisson'],\n",
    "                      'max_features': ['sqrt', 'log2', None, 1]}   \n",
    "    \n",
    "    models = {'AdaBoostRegressor': {'attr': attributes(abr_attributes)},\n",
    "              'BaggingRegressor': {'attr': [{}]},\n",
    "              'ExtraTreesRegressor': {'attr': attributes(etr_attrubites)},\n",
    "              'GradientBoostingRegressor': {'attr': attributes(gbr_attributes)},\n",
    "              'IsolationForest': {'attr': [{}]},\n",
    "              'RandomForestRegressor': {'attr': attributes(rf_attributes)},\n",
    "              'VotingRegressor': {'attr': [{'estimators': estimators}]},\n",
    "              'StackingRegressor': {'attr': [{'estimators': estimators}]}\n",
    "              }\n",
    "    \n",
    "    final_models = {}\n",
    "    \n",
    "    train_set_labels = np.ravel(train_set_labels)\n",
    "    for k,v in sorted(models.items()):\n",
    "        print(k,': ')\n",
    "        print(v['attr'])\n",
    "        for i in range(len(v['attr'])):\n",
    "            fun = getattr(ensemble, k)\n",
    "            reg = fun(**v['attr'][i])\n",
    "            reg.fit(train_set_ready, train_set_labels)\n",
    "\n",
    "            predictions = reg.predict(train_set_ready)\n",
    "\n",
    "            train_mse = mean_squared_error(predictions, train_set_labels)\n",
    "            rmse_training = np.sqrt(train_mse)\n",
    "\n",
    "            scores = cross_val_score(reg, train_set_new_ready, np.ravel(train_set_labels),\n",
    "                                          scoring=\"neg_mean_squared_error\", cv=cv)\n",
    "\n",
    "            rmse_cv = np.sqrt(-scores).mean()\n",
    "            \n",
    "            model_name = str(k) + str(v['attr'][i])\n",
    "            \n",
    "            final_models[model_name] = {'rmse_training': rmse_training, 'rmse_cv': rmse_cv}\n",
    "        \n",
    "    return final_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_neuralnetwork(train_set_ready:np.ndarray, train_set_labels:np.ndarray, cv:int=4):\n",
    "    \"\"\"\n",
    "    Evaluation of neural network with some basic settings for training and cv set.\n",
    "    \"\"\"\n",
    "    \n",
    "    nn_attributes = {'activation': ['identity', 'logistic', 'relu', 'tanh'],\n",
    "     'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "     'learning_rate': ['constant', 'invscaling', 'adaptive']}\n",
    "\n",
    "    attributes_list = attributes(nn_attributes)\n",
    "                \n",
    "    final_models = {}\n",
    "    \n",
    "    for attr in attributes_list:\n",
    "\n",
    "        reg = MLPRegressor(**attr)\n",
    "        reg.fit(train_set_ready, train_set_labels)\n",
    "\n",
    "        predictions = reg.predict(train_set_new_ready)\n",
    "\n",
    "        reg_mse = mean_squared_error(predictions, train_set_labels)\n",
    "        rmse_training = np.sqrt(reg_mse)\n",
    "\n",
    "        reg_scores = cross_val_score(reg, train_set_new_ready, train_set_labels,\n",
    "                                     scoring=\"neg_mean_squared_error\", cv=cv)\n",
    "\n",
    "        rmse_cv = np.sqrt(-reg_scores).mean()\n",
    "        \n",
    "        final_models['MLPRegressor ' + str(attr)] = {'rmse_training': rmse_training, 'rmse_cv': rmse_cv}\n",
    "        \n",
    "    return final_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Classification </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixels_to_image(x:np.ndarray, im_height:int, im_width:int, labels:dict=None, y:np.ndarray=None):\n",
    "    \"\"\"\n",
    "    Displays image from a given row of pixels.\n",
    "    \"\"\"\n",
    "    \n",
    "    image = x.reshape(im_height, im_width)\n",
    "\n",
    "    plt.imshow(image, cmap=mpl.cm.binary, interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    if not (labels is None or y is None):\n",
    "        print(labels[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_class(instances:np.ndarray, images_per_row:int, im_height:int, im_width:int, **options):\n",
    "    \"\"\"\n",
    "    Plots a grid of images for given instances.\n",
    "    \"\"\"\n",
    "    \n",
    "    images_per_row = min(len(instances), images_per_row)\n",
    "\n",
    "    n_rows = (len(instances) - 1) // images_per_row + 1 # compute number of rows using floor division\n",
    "\n",
    "    n_empty = n_rows * images_per_row - len(instances)\n",
    "    padded_instances = np.concatenate([instances, np.zeros((n_empty, im_height * im_width))], axis=0)\n",
    "\n",
    "    image_grid = padded_instances.reshape((n_rows, images_per_row, im_height, im_width))\n",
    "\n",
    "    big_image = image_grid.transpose(0, 2, 1, 3).reshape(n_rows * im_height,\n",
    "                                                         images_per_row * im_width)\n",
    "\n",
    "    plt.imshow(big_image, cmap = mpl.cm.binary, **options)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_cross_val_score(X_train:np.ndarray, y_train:np.ndarray, model, n_splits:int, r_state:int=42):\n",
    "    \"\"\"\n",
    "    Use to have more control in a CV than in sklearn's counterpart.\n",
    "    \"\"\"\n",
    "    \n",
    "    skfolds = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=r_state)\n",
    "    \n",
    "    for train_index, test_index in skfolds.split(X_train, y_train):\n",
    "        \n",
    "        clone_model = clone(model)\n",
    "        \n",
    "        X_train_folds = X_train[train_index]\n",
    "        y_train_folds = y_train[train_index]\n",
    "        \n",
    "        X_test_fold = X_train[test_index]\n",
    "        y_test_fold = y_train[test_index]\n",
    "        \n",
    "        clone_model.fit(X_train_folds, y_train_folds)\n",
    "        \n",
    "        y_pred = clone_model.predict(X_test_fold)\n",
    "        n_correct = sum(y_pred == y_test_fold)\n",
    "        \n",
    "        print(n_correct / len(y_pred))         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall_vs_threshold(precisions:list, recalls:list, thresholds:list):\n",
    "    \"\"\"\n",
    "    Precision-recall vs threshold plot.\n",
    "    \"\"\"\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n",
    "    plt.legend(loc=\"center right\", fontsize=16) \n",
    "    plt.xlabel(\"Threshold\", fontsize=16)        \n",
    "    plt.grid(True)                              \n",
    "    plt.axis([-50000, 50000, 0, 1])             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_vs_recall(precisions:list, recalls:list):\n",
    "    \"\"\"\n",
    "    Precision vs recall plot.\n",
    "    \"\"\"\n",
    "    plt.plot(recalls, precisions, \"b-\", linewidth=2)\n",
    "    plt.xlabel(\"Recall\", fontsize=16)\n",
    "    plt.ylabel(\"Precision\", fontsize=16)\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr:list, tpr:list, label=None):\n",
    "    \"\"\"\n",
    "    Roc-curve plot.\n",
    "    \"\"\"\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--') # dashed diagonal\n",
    "    plt.axis([0, 1, 0, 1])                                    \n",
    "    plt.xlabel('False Positive Rate (Fall-Out)', fontsize=16) \n",
    "    plt.ylabel('True Positive Rate (Recall)', fontsize=16)    \n",
    "    plt.grid(True)                                            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
